{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac051271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de5e80",
   "metadata": {},
   "source": [
    "Read file from DUC_TEXT/test\n",
    "Create a dictionary save all the metadata of sentences\n",
    "Create unique sentence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe960101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file from DUC_TEXT/test\n",
    "\n",
    "file_path = \"DUC_TEXT/test/d112h\"  \n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    doc_file = file.read()\n",
    "\n",
    "# print(\"Read file from DUC_TEXT/test\")\n",
    "# print(doc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65296f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary save all the metadata of sentences\n",
    "def parse_doc (doc_file):\n",
    "    \"\"\"\n",
    "    Parse the document file and extract sentences metadata.\n",
    "    \n",
    "    Args:\n",
    "        doc_file (str): The content of the document file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with sentence_id as keys and metadata as values.\n",
    "    \"\"\"\n",
    "    sentences_dict = {}\n",
    "    # Create unique sentence_id\n",
    "    # Initialize sentence_id to 0\n",
    "    sentence_id = 0\n",
    "\n",
    "    # Find all sentences tags and their content in the document\n",
    "    sentence_matches = re.findall(r'<s\\s+docid=\"([^\"]+)\"\\s+num=\"([^\"]+)\"\\s+wdcount=\"([^\"]+)\">\\s*(.*?)\\s*</s>', doc_file, re.DOTALL)\n",
    "\n",
    "    for doc_id, num, wdcount, sentence_text in sentence_matches:\n",
    "        sentences_dict[sentence_id] = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"num\": num,\n",
    "            \"wdcount\": int(wdcount),\n",
    "            \"sentence_text\": sentence_text.strip()\n",
    "        }\n",
    "        sentence_id += 1    \n",
    "    return sentences_dict\n",
    "\n",
    "sentences_dict = parse_doc(doc_file)\n",
    "# Print the sentences dictionary\n",
    "# print(sentences_dict)\n",
    "# for sid, metadata in sentences_dict.items():\n",
    "#     print(f\"Sentence ID: {sid}, Metadata: {metadata}\")\n",
    "# print(f\"Total sentences processed: {len(sentences_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d326d",
   "metadata": {},
   "source": [
    "Calculate connection by n common word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5164b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_connection(sentence1, sentence2, min_common_words=8):\n",
    "    \"\"\"\n",
    "    Check if two sentences have a connection based on common words.\n",
    "    \n",
    "    Args:\n",
    "        sentence1 (str): The first sentence.\n",
    "        sentence2 (str): The second sentence.\n",
    "        mincommon_words (int): Minimum number of common words to consider a connection.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if there is a connection, False otherwise.\n",
    "    \"\"\"\n",
    "    words1 = set(re.findall(r'\\b\\w+\\b', sentence1.lower()))\n",
    "    words2 = set(re.findall(r'\\b\\w+\\b', sentence2.lower()))\n",
    "    common_words = words1.intersection(words2)\n",
    "    return len(common_words) >= min_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616373b",
   "metadata": {},
   "source": [
    "Create connection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4b2e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection_matrix(sentences_dict):\n",
    "    \"\"\"\n",
    "    Create a connection matrix based on the sentences metadata.\n",
    "    \n",
    "    Args:\n",
    "        sentences_dict (dict): A dictionary with sentence_id as keys and metadata as values.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A balance two-dimentional matrix where matrix[i][j] is True\n",
    "                    if sentence i and sentence j have connection, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    num_sentences = len(sentences_dict)\n",
    "    connection_matrix = np.full((num_sentences, num_sentences), False, dtype=bool)\n",
    "\n",
    "    # Get all sentence texts\n",
    "    sentence_texts = [sentences_dict[i]['sentence_text'] for i in range(num_sentences)]\n",
    "\n",
    "    # Compare each pair of sentences\n",
    "    for i in range(num_sentences):\n",
    "        for j in range(i + 1, num_sentences):\n",
    "            if has_connection(sentence_texts[i], sentence_texts[j]):\n",
    "                connection_matrix[i][j] = True\n",
    "                connection_matrix[j][i] = True\n",
    "\n",
    "\n",
    "    return connection_matrix\n",
    "# import create_connection_matrix as ccm\n",
    "# connection_matrix = ccm.create_connection_matrix(sentences_dict)\n",
    "# Print the connection matrix\n",
    "# print(\"Connection Matrix:\")\n",
    "connection_matrix = create_connection_matrix(sentences_dict)\n",
    "# print(connection_matrix)\n",
    "# print(\"Connection Details:\")\n",
    "# for i in range(connection_matrix.shape[0]):\n",
    "#     for j in range(connection_matrix.shape[1]):\n",
    "#         print(connection_matrix[i][j], end=' ')\n",
    "#     print()  # New line for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6f0bc",
   "metadata": {},
   "source": [
    "Calculate pageRank score\n",
    "The PageRank formula is defined as:\n",
    "\n",
    "$$\n",
    "PR(i) = \\frac{1 - d}{N} + d \\sum_{j \\in M(i)} \\frac{PR(j)}{L(j)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $PR(i)$ is the PageRank of node $i$\n",
    "- $d$ is the damping factor (usually 0.85)\n",
    "- $N$ is the total number of nodes\n",
    "- $M(i)$ are nodes linking to $i$\n",
    "- $L(j)$ is the number of outgoing links from node $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04d5f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pagerank(connection_matrix, d=0.85, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate PageRank scores based on the connection matrix.\n",
    "    \n",
    "    Args:\n",
    "        connection_matrix (np.ndarray): The connection matrix.\n",
    "        d (float): Damping factor.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "                    This stops the algorithm if it doesnt converge quickly to avoid infinite loops.\n",
    "        tol (float): Tolerance for convergence. \n",
    "                    If the change in PageRank scores between iterations is less than this value, \n",
    "                    the algorithm stops early (it's considered converged)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: PageRank scores for each sentence.\n",
    "    \"\"\"\n",
    "    # Find the number of nodes in the connection matrix by getting the number of rows of adjacency matrix\n",
    "    num_nodes = connection_matrix.shape[0]\n",
    "    # Convert matrix elements to float\n",
    "    transition_matrix = connection_matrix.astype(float) \n",
    "    # Sum up each row to get the total number of connections for each sentence\n",
    "    row_sums = transition_matrix.sum(axis=1)\n",
    "\n",
    "    # Normalize the transition matrix by dividing each row by its sum\n",
    "    # This ensures that the sum of probabilities in each row equals 1\n",
    "    for i in range(num_nodes):\n",
    "        if row_sums[i] > 0:\n",
    "            transition_matrix[i] /= row_sums[i]\n",
    "        else:\n",
    "            # Handle dangling nodes (nodes with no outgoing edges)\n",
    "            # Assign equal probability to all nodes\n",
    "            transition_matrix[i] = np.ones(num_nodes) / num_nodes\n",
    "    # Initialize PageRank scores to 1/n for each node\n",
    "    pagerank_scores = np.ones(num_nodes) / num_nodes\n",
    "    # Iterate to update PageRank scores\n",
    "    for _ in range(max_iter):\n",
    "        new_pagerank_scores = np.zeros(num_nodes)\n",
    "        for i in range(num_nodes):\n",
    "            # Calculate the new PageRank score for each node\n",
    "            new_pagerank_scores[i] = (1 - d) / num_nodes + d * np.sum(transition_matrix[:, i] * pagerank_scores)\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(new_pagerank_scores - pagerank_scores, ord=1) < tol:\n",
    "            break\n",
    "        pagerank_scores = new_pagerank_scores\n",
    "    return pagerank_scores\n",
    "pagerank_scores = calculate_pagerank(connection_matrix)\n",
    "# Print the PageRank scores\n",
    "# print(\"PageRank Scores:\")\n",
    "# for i, score in enumerate(pagerank_scores):\n",
    "#     print(f\"Sentence ID {i}: {score:.4f} - {sentences_dict[i]['sentence_text']}\")    \n",
    "    \n",
    "                                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c64a16",
   "metadata": {},
   "source": [
    "Get the 10% highest score sentences to create a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7695c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Sentences:\n",
      "Sentence ID 16: 0.0463 - In his report Sir Robert points to 'certain weaknesses' accepted by the MGN board: Internal controls and operating procedures which failed to identify related party transactions and bring them to the attention of independent directors for approval; Bank mandates authorised by Robert Maxwell and Mr Stoney which permitted the movement of group funds on the authority of Maxwell or directors who were also directors of Maxwell-controlled companies; The audit committee of non-executive directors, which might have reviewed systems and mandates, but was not convened; The finance department's inadequate authority to verify and record the treasury department's activities.\n",
      "Sentence ID 99: 0.0367 - Press coverage of the late publisher since his death has already caused deep concern to the Maxwell brothers' lawyers . Mr Alun Jones QC, Kevin Maxwell's barrister, led calls for reporting restrictions to be placed on a recent High Court ruling that Robert Maxwell had been fraudulent in his dealings with shares in Berlitz, the publishing company.\n",
      "Sentence ID 17: 0.0346 - The report details a Pounds 50m loan made by Bankers Trust in London last October which appears to have been used to pay off a loan from Bankers Trust in New York to Robert Maxwell Group, parent of the Maxwell private interests, Separately, the statement highlights three transfers of more than Pounds 40m from MGN to Goldman Sachs - Pounds 11m of this was transferred on Robert Maxwell's signature to pay for previous dealings in Maxwell Communication Corporation stock.\n",
      "Sentence ID 0: 0.0281 - MR MICHAEL STONEY, a senior executive in a number of Maxwell companies, is named as one of three people primarily responsible for more than Pounds 180m of 'unusual' payments from Mirror Group Newspapers bank accounts during the last financial year, according to the chairman's statement released with MGN accounts yesterday.\n",
      "Sentence ID 47: 0.0269 - Meanwhile, a director of a secretive Swiss trust, Mr Werner Rechsteiner, has broken his silence and has admitted that transfers of MCC shares to his trust, which are at the centre of an investigation by the Serious Fraud Office, were made on the instructions of Robert Maxwell.\n",
      "Sentence ID 63: 0.0246 - On May 29 last year, Mr Kevin Maxwell sent a fax to Mr Larry Wood, an executive director of Goldman Sachs, telling him that two parcels of 12.5m MCC shares each would be bought by the Swiss trusts with Pounds 55.33m provided by BIT, a Maxwell private company.\n",
      "Sentence ID 46: 0.0227 - DOCUMENTS which show for the first time that both Mr Robert Maxwell and his son Kevin were intimately involved in substantial purchases of shares in Maxwell Communication Corporation, one of their own public companies, have been obtained by the Financial Times.\n",
      "Sentence ID 77: 0.0195 - 'There is no evidence to suggest that Maxwell actually was a strong player or that he played in any tournaments,' said Mr Malcolm Pein, international chess master and director of Chess and Bridge, which yesterday took over the business and assets of Maxwell Macmillan Chess and Bridge.\n",
      "Sentence ID 69: 0.0181 - As a director of MGPT and as a trustee of MCCPT, he told Mr Wood to pay each pension fund what it was owed to the NatWest account of BIT, which Mr Maxwell described as 'nominee' for the two pension funds.\n",
      "Sentence ID 198: 0.0169 - \"I have to say to myself that given the sequence of events and looking at the whole picture, that a lot of it is fair comment,\" Kevin Maxwell was quoted as saying by the Daily Mirror.\n",
      "Sentence ID 65: 0.0166 - Two other faxes sent by Mr Kevin Maxwell to Mr Wood on the same day show that the former was equally involved in the other end of the transaction, the sale of the 25m shares.\n",
      "Sentence ID 115: 0.0164 - The writs also allege that on May 28 1991 - the same date Mr Kevin Maxwell arranged for the pension fund share transaction to be paid for - Goldman was due to receive Dollars 58.2m for an unrelated transaction selling MCC stock to an unnamed American lawyer 'with close connections to Robert Maxwell'.\n",
      "Sentence ID 49: 0.0147 - The FT has also obtained a letter and has seen a corroborating fax which shows that Mr Kevin Maxwell was intimately involved in the purchase of 9m shares by Yakosa and a further 16m shares by Servex, another Swiss Trust.\n",
      "Sentence ID 70: 0.0145 - In other words, he told Mr Wood that the shares were being bought for the Swiss trusts with funds provided by BIT and that these funds should then be sent by Goldman back to BIT.\n",
      "Sentence ID 120: 0.0138 - The writs say that Goldman and Sheinberg 'made no reasonable effort to determine who had actual authority to direct for the pension fund that the shares be sold and where the more than Dollars 47m in proceeds from the transfer of the 12.5m shares should go'.\n",
      "Sentence ID 39: 0.0137 - The bank told both Robert Maxwell and Mr Kevin Maxwell that it was concerned that repayment had not been made, but it did not discuss the problem with other banks or with the Bank of England.\n",
      "Sentence ID 118: 0.0133 - On May 23 he told Goldman to remit the proceeds of the sale not to the pension schemes but to Bishopsgate Investment Trust, which Goldman knew or should have known was controlled by the Maxwell family.\n",
      "Sentence ID 76: 0.0124 - THE LATE Mr Robert Maxwell liked to think of himself as a 'strong ' chess player and there was always a chess set in his suite in his London headquarters.\n",
      "Sentence ID 62: 0.0122 - The FT has however obtained documents showing that Mr Kevin Maxwell was closely involved in the process of paying for 25m MCC shares on behalf of two Swiss trusts, Yakosa and Servex.\n",
      "Sentence ID 135: 0.0122 - Maxwell's comments were made to reporters at the annual meeting in New York of Maxwell's Berlitz International and were confirmed later by a spokesman for Maxwell Communications, the investor's London-based holding company.\n",
      "Sentence ID 110: 0.0121 - Two writs have been filed alleging that Goldman Sachs, the US-based investment bank, assisted in diverting Pounds 55m from two pension schemes controlled by Robert Maxwell to ensure its own debts from Maxwell interests would be repaid.\n",
      "Sentence ID 4: 0.0115 - He says legal action may be taken against a number of organisations, including Goldman Sachs, the US investment bank, over more than Pounds 40m in transfers from MGN if the bank was aware that they were 'effected for improper purposes'.\n",
      "Sentence ID 100: 0.0115 - Turning down his request, the judge asked him: 'Is it going to be your client's defence that Mr Robert Maxwell was not guilty of misappropriation'?\n"
     ]
    }
   ],
   "source": [
    "# summary_sentences = sorted(range(len(pagerank_scores)), key=lambda i: pagerank_scores[i], reverse=True)[:int(0.1 * len(pagerank_scores))]\n",
    "# summary = [sentence_dict[i]['sentence_text'] for i in summary_sentences]\n",
    "# print(\"\\nSummary Sentences:\")\n",
    "# for sentence in summary:\n",
    "#     print(sentence)\n",
    "# Get the 10% highest score sentences to create a summary\n",
    "summary_sentences = sorted(range(len(pagerank_scores)), key=lambda i: pagerank_scores[i], reverse=True)[:int(0.1 * len(pagerank_scores))]\n",
    "print(\"Summary Sentences:\")\n",
    "for i in summary_sentences:\n",
    "    print(f\"Sentence ID {i}: {pagerank_scores[i]:.4f} - {sentences_dict[i]['sentence_text']}\")\n",
    "# summary = [sentence_dict[i]['sentence_text'] for i in summary_sentences]\n",
    "# print(\"\\nSummary Sentences:\")\n",
    "# for sentence in summary:\n",
    "#     print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bf407cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10% sentences written to output/d112h_commonword\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get the input file name without the extension\n",
    "input_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(output_dir, f'{input_filename}_commonword')\n",
    "\n",
    "# Write the top sentences to the output file in the desired format\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    for sentence_id in summary_sentences:\n",
    "        doc_id = sentences_dict[sentence_id]['doc_id']\n",
    "        wdcount = sentences_dict[sentence_id]['wdcount']\n",
    "        num = sentences_dict[sentence_id]['num']\n",
    "        sentence_text = sentences_dict[sentence_id]['sentence_text']\n",
    "        # Reconstruct the original sentence tag format\n",
    "        outfile.write(f'<s doc_id=\"{doc_id}\" num=\"{num}\" wdcount=\"{wdcount}\"> {sentence_text}</s>\\n')\n",
    "\n",
    "print(f\"\\nTop 10% sentences written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2adf71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the result with the summay file has given in DUC_SUM folder\n",
    "\n",
    "preference_sum_path = \"DUC_SUM/d112h\"  \n",
    "with open(preference_sum_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    preference_sum_file = file.read()\n",
    "\n",
    "preference_sum_dict = parse_doc(preference_sum_file)\n",
    "# compare the summary_sentences with the preference summary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f21aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 out of 11 summary sentences are in the preference summary (18.18%)\n"
     ]
    }
   ],
   "source": [
    "# Get the set of (doc_id, num) for sentences in preference_sum_dict\n",
    "preference_keys = set((v['doc_id'], v['num']) for v in preference_sum_dict.values())\n",
    "\n",
    "# Count how many summary_sentences are present in preference_sum_dict by (doc_id, num)\n",
    "matched = 0\n",
    "for sid in summary_sentences:\n",
    "    sent = sentences_dict[sid]\n",
    "    if (sent['doc_id'], sent['num']) in preference_keys:\n",
    "        matched += 1\n",
    "\n",
    "percentage = (matched / len(preference_sum_dict)) * 100 if preference_sum_dict else 0\n",
    "print(f\"{matched} out of {len(preference_sum_dict)} summary sentences are in the preference summary ({percentage:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
